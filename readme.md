# ETL-процессы
В данном репозитории содержатся пайпы для наполнения данными хранилища, по которому будет осуществлять поиск видеозаписей

Перед начало разбора кода просьба ознакомиться с описанием того, какую логику пресследовали экстракте данных с видео

- [Ознакомление и анализ полученной выборки](https://www.kaggle.com/code/dnikonorov/data-analysis)
- [Выработка алгоритма для обогащения данных](https://www.kaggle.com/code/dnikonorov/preprocess-description-with-examples)

Подробнее по структуре пакетов и описание отдельных файлов:

<pre>
├── automatic_speech_recognition - содержит код для распознования текста с видео
├── data_union - содержит код для объединения результатов работы модели
├── models - модели для работы локально (появятся после выполнения models_to_local.py)
├── image_captioning - содержит код для распознавания текста с видео
├── notebooks - содержит jupiter-тетрадки, опубликованные в Kaggle и описанные выше
├── translate - код для перевода текста на русский 
├── main.py - первый пайплан для сбора данных в обогащенные csv
├── main_two.py - второй пайплайн для публикации обогащенных данных с csv в хранилище
├── requirements.txt - зависимости
├── general_data.csv - обогащенные данные, на которых построен индекс
└── source_dataset.csv - исходный датасет, полученный от держателей кейса
</pre>


# Инструкция для работы локально
В первую очередь необходимо настроить конфигурацию конфигурацию

#### Режим запуска файле global_env.py
- если хотите собирать все сразу - выставляем ETL_MODE=EtlMode.FULL
- если собирать только речь с видео - выставляем ETL_MODE=EtlMode.ONLY_SPEECH
- если осуществлять обогащение по контенту с видео - выставляем ETL_MODE=EtlMode.ONLY_CAPTIONING

#### Остальные параметры в global_env.py
- DATASET_PATH - выставить корректный путь до исходного датасета из ТЗ
- TEMP_DIRECTORY_PATH - выставить директорию, куда будут складываться temp-файлы и результаты работы модели
- CPU_COUNT - на скольких ядрах запускать скрипт. Рекомендация для MAC OS - не больше 6, по умолчанию стоит 1
- START_INTERVAL - с какой записи исходного фрейма начинаем сборку
- END_INTERVAL - на какой записи исходного фрейма заканчиваем сборку
- LOCAL_MODELS_PATH - откуда забирать модели для работы локально. Прописать путь до директории проекта аля project.basedir + /models/

#### Системные требования для старта помимо установленной cuda
- не забыть проверить наличие ffmpeg на ПК. Нужно для whisper
- для того, чтобы заработал переводчик из пакета translator нужна java 11
- поставить через pip все зависимости из requirements.txt в ту среду, откуда будете запускать скрипт



После того, как заменили параметры и выполнили системные требования необходимо:
- выполнить файл models_to_local.py **ИЗ ДИРЕКТОРИИ С ПРОЕКТОМ**, чтобы вытянуть модели к себе
- стартануть main.py