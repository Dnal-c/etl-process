{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-05T14:38:48.219064Z",
     "iopub.status.busy": "2024-06-05T14:38:48.218639Z",
     "iopub.status.idle": "2024-06-05T14:39:32.837270Z",
     "shell.execute_reply": "2024-06-05T14:39:32.836193Z",
     "shell.execute_reply.started": "2024-06-05T14:38:48.219021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.10 (from versions: 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.1, 2.16.0rc0, 2.16.1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.10\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: whisperx in /opt/anaconda3/lib/python3.11/site-packages (3.1.1)\n",
      "Requirement already satisfied: torch>=2 in /opt/anaconda3/lib/python3.11/site-packages (from whisperx) (2.3.0)\n",
      "Requirement already satisfied: torchaudio>=2 in /opt/anaconda3/lib/python3.11/site-packages (from whisperx) (2.3.0)\n",
      "Requirement already satisfied: faster-whisper==1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from whisperx) (1.0.0)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.11/site-packages (from whisperx) (4.39.3)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (from whisperx) (2.2.1)\n",
      "Requirement already satisfied: setuptools>=65 in /opt/anaconda3/lib/python3.11/site-packages (from whisperx) (68.2.2)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.11/site-packages (from whisperx) (3.8.1)\n",
      "Requirement already satisfied: pyannote.audio==3.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from whisperx) (3.1.1)\n",
      "Requirement already satisfied: av==11.* in /opt/anaconda3/lib/python3.11/site-packages (from faster-whisper==1.0.0->whisperx) (11.0.0)\n",
      "Requirement already satisfied: ctranslate2<5,>=4.0 in /opt/anaconda3/lib/python3.11/site-packages (from faster-whisper==1.0.0->whisperx) (4.2.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from faster-whisper==1.0.0->whisperx) (0.23.2)\n",
      "Requirement already satisfied: tokenizers<0.16,>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from faster-whisper==1.0.0->whisperx) (0.15.2)\n",
      "Requirement already satisfied: onnxruntime<2,>=1.14 in /opt/anaconda3/lib/python3.11/site-packages (from faster-whisper==1.0.0->whisperx) (1.18.0)\n",
      "Requirement already satisfied: asteroid-filterbanks>=0.4 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.audio==3.1.1->whisperx) (0.4.0)\n",
      "Requirement already satisfied: einops>=0.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.audio==3.1.1->whisperx) (0.8.0)\n",
      "Requirement already satisfied: lightning>=2.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.audio==3.1.1->whisperx) (2.2.5)\n",
      "Requirement already satisfied: omegaconf<3.0,>=2.1 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.audio==3.1.1->whisperx) (2.3.0)\n",
      "Requirement already satisfied: pyannote.core>=5.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.audio==3.1.1->whisperx) (5.0.0)\n",
      "Requirement already satisfied: pyannote.database>=5.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.audio==3.1.1->whisperx) (5.1.0)\n",
      "Requirement already satisfied: pyannote.metrics>=3.2 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.audio==3.1.1->whisperx) (3.2.1)\n",
      "Requirement already satisfied: pyannote.pipeline>=3.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.audio==3.1.1->whisperx) (3.0.1)\n",
      "Requirement already satisfied: pytorch-metric-learning>=2.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.audio==3.1.1->whisperx) (2.5.0)\n",
      "Requirement already satisfied: rich>=12.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.audio==3.1.1->whisperx) (13.3.5)\n",
      "Requirement already satisfied: semver>=3.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.audio==3.1.1->whisperx) (3.0.2)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.audio==3.1.1->whisperx) (0.12.1)\n",
      "Requirement already satisfied: speechbrain>=0.5.14 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.audio==3.1.1->whisperx) (1.0.0)\n",
      "Requirement already satisfied: tensorboardX>=2.6 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.audio==3.1.1->whisperx) (2.6.2.2)\n",
      "Requirement already satisfied: torch-audiomentations>=0.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.audio==3.1.1->whisperx) (0.11.1)\n",
      "Requirement already satisfied: torchmetrics>=0.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.audio==3.1.1->whisperx) (1.4.0.post0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch>=2->whisperx) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from torch>=2->whisperx) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch>=2->whisperx) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch>=2->whisperx) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch>=2->whisperx) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch>=2->whisperx) (2023.10.0)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.11/site-packages (from nltk->whisperx) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.11/site-packages (from nltk->whisperx) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.11/site-packages (from nltk->whisperx) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from nltk->whisperx) (4.65.0)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->whisperx) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->whisperx) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->whisperx) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->whisperx) (2023.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from transformers->whisperx) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.11/site-packages (from transformers->whisperx) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (from transformers->whisperx) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.11/site-packages (from transformers->whisperx) (0.4.3)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from lightning>=2.0.1->pyannote.audio==3.1.1->whisperx) (0.11.2)\n",
      "Requirement already satisfied: pytorch-lightning in /opt/anaconda3/lib/python3.11/site-packages (from lightning>=2.0.1->pyannote.audio==3.1.1->whisperx) (2.2.5)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/anaconda3/lib/python3.11/site-packages (from omegaconf<3.0,>=2.1->pyannote.audio==3.1.1->whisperx) (4.9.3)\n",
      "Requirement already satisfied: coloredlogs in /opt/anaconda3/lib/python3.11/site-packages (from onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/anaconda3/lib/python3.11/site-packages (from onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.11/site-packages (from onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx) (3.20.3)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.core>=5.0.0->pyannote.audio==3.1.1->whisperx) (2.4.0)\n",
      "Requirement already satisfied: scipy>=1.1 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.core>=5.0.0->pyannote.audio==3.1.1->whisperx) (1.11.4)\n",
      "Requirement already satisfied: typer>=0.12.1 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.database>=5.0.1->pyannote.audio==3.1.1->whisperx) (0.12.3)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx) (1.4.2)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx) (0.6.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx) (0.9.0)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx) (3.8.4)\n",
      "Requirement already satisfied: optuna>=3.1 in /opt/anaconda3/lib/python3.11/site-packages (from pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx) (3.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->whisperx) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich>=12.0.0->pyannote.audio==3.1.1->whisperx) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich>=12.0.0->pyannote.audio==3.1.1->whisperx) (2.15.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from soundfile>=0.12.1->pyannote.audio==3.1.1->whisperx) (1.16.0)\n",
      "Requirement already satisfied: hyperpyyaml in /opt/anaconda3/lib/python3.11/site-packages (from speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx) (1.2.2)\n",
      "Requirement already satisfied: sentencepiece in /opt/anaconda3/lib/python3.11/site-packages (from speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx) (0.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch>=2->whisperx) (1.3.0)\n",
      "Requirement already satisfied: julius<0.3,>=0.2.3 in /opt/anaconda3/lib/python3.11/site-packages (from torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (0.2.7)\n",
      "Requirement already satisfied: librosa>=0.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (0.10.2.post1)\n",
      "Requirement already satisfied: torch-pitch-shift>=1.2.2 in /opt/anaconda3/lib/python3.11/site-packages (from torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (1.2.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=2->whisperx) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers->whisperx) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers->whisperx) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers->whisperx) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers->whisperx) (2024.2.2)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio==3.1.1->whisperx) (2.21)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/lib/python3.11/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx) (3.9.3)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/anaconda3/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (3.0.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/anaconda3/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (0.59.0)\n",
      "Requirement already satisfied: pooch>=1.1 in /opt/anaconda3/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (1.8.1)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/anaconda3/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (0.3.7)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (1.0.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=12.0.0->pyannote.audio==3.1.1->whisperx) (0.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx) (3.0.9)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx) (1.13.1)\n",
      "Requirement already satisfied: colorlog in /opt/anaconda3/lib/python3.11/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx) (6.8.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx) (2.0.25)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx) (2.2.0)\n",
      "Requirement already satisfied: primePy>=1.3 in /opt/anaconda3/lib/python3.11/site-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (1.3)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio==3.1.1->whisperx) (1.5.4)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/anaconda3/lib/python3.11/site-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx) (10.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in /opt/anaconda3/lib/python3.11/site-packages (from hyperpyyaml->speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx) (0.18.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx) (1.9.3)\n",
      "Requirement already satisfied: Mako in /opt/anaconda3/lib/python3.11/site-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx) (1.3.5)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/anaconda3/lib/python3.11/site-packages (from numba>=0.51.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from pooch>=1.1->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (3.10.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/anaconda3/lib/python3.11/site-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx) (0.2.8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googletrans==4.0.0-rc1 in /opt/anaconda3/lib/python3.11/site-packages (4.0.0rc1)\n",
      "Requirement already satisfied: httpx==0.13.3 in /opt/anaconda3/lib/python3.11/site-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.11/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.2.2)\n",
      "Requirement already satisfied: hstspreload in /opt/anaconda3/lib/python3.11/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.6.1)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
      "Requirement already satisfied: chardet==3.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
      "Requirement already satisfied: idna==2.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in /opt/anaconda3/lib/python3.11/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
      "Requirement already satisfied: httpcore==0.9.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
      "Requirement already satisfied: h2==3.* in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in /opt/anaconda3/lib/python3.11/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorflow==2.10 \n",
    "!pip install whisperx\n",
    "!pip install googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T14:39:32.839865Z",
     "iopub.status.busy": "2024-06-05T14:39:32.839551Z",
     "iopub.status.idle": "2024-06-05T14:39:47.667728Z",
     "shell.execute_reply": "2024-06-05T14:39:47.666603Z",
     "shell.execute_reply.started": "2024-06-05T14:39:32.839835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: protobuf==3.19.*\r\n"
     ]
    }
   ],
   "source": [
    "!pip install protobuf==3.19.*\n",
    "!export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T14:39:47.669515Z",
     "iopub.status.busy": "2024-06-05T14:39:47.669195Z",
     "iopub.status.idle": "2024-06-05T14:39:47.674458Z",
     "shell.execute_reply": "2024-06-05T14:39:47.673461Z",
     "shell.execute_reply.started": "2024-06-05T14:39:47.669486Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T14:39:47.675967Z",
     "iopub.status.busy": "2024-06-05T14:39:47.675659Z",
     "iopub.status.idle": "2024-06-05T14:39:47.687783Z",
     "shell.execute_reply": "2024-06-05T14:39:47.686856Z",
     "shell.execute_reply.started": "2024-06-05T14:39:47.675944Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import uuid\n",
    "import shutil\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import whisperx\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T14:39:47.690728Z",
     "iopub.status.busy": "2024-06-05T14:39:47.690456Z",
     "iopub.status.idle": "2024-06-05T14:39:47.699066Z",
     "shell.execute_reply": "2024-06-05T14:39:47.698241Z",
     "shell.execute_reply.started": "2024-06-05T14:39:47.690706Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import GPT2TokenizerFast, ViTImageProcessor, pipeline\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "# set device to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T14:39:47.700547Z",
     "iopub.status.busy": "2024-06-05T14:39:47.700209Z",
     "iopub.status.idle": "2024-06-05T14:39:47.710269Z",
     "shell.execute_reply": "2024-06-05T14:39:47.709429Z",
     "shell.execute_reply.started": "2024-06-05T14:39:47.700515Z"
    }
   },
   "outputs": [],
   "source": [
    "# функция, определяющая, является ли строка URL-адресом или нет\n",
    "def is_url(string):\n",
    "    try:\n",
    "        result = parse.urlparse(string)\n",
    "        return all([result.scheme, result.netloc, result.path])\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "# фукнция загрузки изображения\n",
    "def load_image(image_path):\n",
    "    if is_url(image_path):\n",
    "        return Image.open(requests.get(image_path, stream=True).raw)\n",
    "    elif os.path.exists(image_path):\n",
    "        return Image.open(image_path)\n",
    "        \n",
    "# функция инференса\n",
    "def get_caption(model, image_processor, tokenizer, image_path):\n",
    "    image = load_image(image_path)\n",
    "    # предобработка\n",
    "    img = image_processor(image, return_tensors=\"pt\").to(device)\n",
    "    # генерируем описание\n",
    "    output = model.generate(**img)\n",
    "    # декодим вывод\n",
    "    caption = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "    return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.2.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.3.0. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import whisperx\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "compute_type = \"int8\"\n",
    "whisper_model = whisperx.load_model(\"large-v2\", device=device, compute_type=compute_type)\n",
    "\n",
    "def transcribe_video(input_video):\n",
    "    batch_size = 32\n",
    "\n",
    "    audio = whisperx.load_audio(input_video)\n",
    "    result = whisper_model.transcribe(audio, batch_size=batch_size, language=\"ru\")\n",
    "\n",
    "    model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
    "    result = whisperx.align(result[\"segments\"], model_a, metadata, audio, device, return_char_alignments=False)\n",
    "\n",
    "    segments = result['segments']\n",
    "    texts = []\n",
    "    for seg in segments:\n",
    "        texts.append(seg['text'])\n",
    "    return ' '.join(texts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T14:41:33.833234Z",
     "iopub.status.busy": "2024-06-05T14:41:33.832889Z",
     "iopub.status.idle": "2024-06-05T14:41:33.853306Z",
     "shell.execute_reply": "2024-06-05T14:41:33.852240Z",
     "shell.execute_reply.started": "2024-06-05T14:41:33.833208Z"
    }
   },
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "def translate_frames_caption(source_texts):\n",
    "    translated_texts = []\n",
    "    for res in source_texts:\n",
    "        text = translator.translate(res, src='en', dest='ru')\n",
    "        translated_texts.append(text.text)\n",
    "    return translated_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T14:39:50.661449Z",
     "iopub.status.busy": "2024-06-05T14:39:50.660784Z",
     "iopub.status.idle": "2024-06-05T14:39:50.670824Z",
     "shell.execute_reply": "2024-06-05T14:39:50.670000Z",
     "shell.execute_reply.started": "2024-06-05T14:39:50.661416Z"
    }
   },
   "outputs": [],
   "source": [
    "# функция, определяющая, является ли строка URL-адресом или нет\n",
    "def is_url(string):\n",
    "    try:\n",
    "        result = parse.urlparse(string)\n",
    "        return all([result.scheme, result.netloc, result.path])\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "# фукнция загрузки изображения\n",
    "def load_image(image_path):\n",
    "    if is_url(image_path):\n",
    "        return Image.open(requests.get(image_path, stream=True).raw)\n",
    "    elif os.path.exists(image_path):\n",
    "        return Image.open(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T14:39:50.672477Z",
     "iopub.status.busy": "2024-06-05T14:39:50.672193Z",
     "iopub.status.idle": "2024-06-05T14:39:50.687027Z",
     "shell.execute_reply": "2024-06-05T14:39:50.686124Z",
     "shell.execute_reply.started": "2024-06-05T14:39:50.672454Z"
    }
   },
   "outputs": [],
   "source": [
    "# Параметр, отвечающий за то, куда будем складывать файлы\n",
    "BASE_PATH = '../'\n",
    "# Параметр, отвечающий за то, сколько фреймов резать за секунду\n",
    "SAVING_FRAMES_PER_SECOND = .5\n",
    "\n",
    "\n",
    "def format_timedelta(td):\n",
    "    \"\"\"Служебная функция для классного форматирования объектов timedelta (например, 00:00:20.05)\n",
    "    исключая микросекунды и сохраняя миллисекунды\"\"\"\n",
    "    result = str(td)\n",
    "    try:\n",
    "        result, ms = result.split(\".\")\n",
    "    except ValueError:\n",
    "        return result + \".00\".replace(\":\", \"-\")\n",
    "    ms = int(ms)\n",
    "    ms = round(ms / 1e4)\n",
    "    return f\"{result}.{ms:02}\".replace(\":\", \"-\")\n",
    "\n",
    "\n",
    "def get_saving_frames_durations(cap, saving_fps):\n",
    "    \"\"\"Функция, которая возвращает список длительностей, в которые следует сохранять кадры.\"\"\"\n",
    "    s = []\n",
    "    # получаем продолжительность клипа, разделив количество кадров на количество кадров в секунду\n",
    "    clip_duration = cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)\n",
    "    # используйте np.arange () для выполнения шагов с плавающей запятой\n",
    "    for i in np.arange(0, clip_duration, 1 / saving_fps):\n",
    "        s.append(i)\n",
    "    return s\n",
    "\n",
    "\n",
    "def create_temp_directory_with_frames(video_file):\n",
    "    uid = uuid.uuid1()\n",
    "    dirname_str = BASE_PATH + str(uid) + '-opencv'\n",
    "    dirname = Path(dirname_str)\n",
    "    # создаем папку по названию видео файла\n",
    "    if not os.path.isdir(dirname_str):\n",
    "        dirname.mkdir(exist_ok=True)\n",
    "    # создаем папку по названию видео файла\n",
    "    # читать видео файл\n",
    "    capture = cv2.VideoCapture(video_file)\n",
    "    # получить FPS видео\n",
    "    fps = capture.get(cv2.CAP_PROP_FPS)\n",
    "    # если SAVING_FRAMES_PER_SECOND выше видео FPS, то установите его на FPS (как максимум)\n",
    "    saving_frames_per_second = min(fps, SAVING_FRAMES_PER_SECOND)\n",
    "    # получить список длительностей для сохранения\n",
    "    saving_frames_durations = get_saving_frames_durations(capture, saving_frames_per_second)\n",
    "    # запускаем цикл\n",
    "    count = 0\n",
    "    frame_insert_count = 1\n",
    "    while True:\n",
    "        is_read, frame = capture.read()\n",
    "        if not is_read:\n",
    "            # выйти из цикла, если нет фреймов для чтения\n",
    "            break\n",
    "        # получаем продолжительность, разделив количество кадров на FPS\n",
    "        frame_duration = count / fps\n",
    "        try:\n",
    "            # получить самую раннюю продолжительность для сохранения\n",
    "            closest_duration = saving_frames_durations[0]\n",
    "        except IndexError:\n",
    "            # список пуст, все кадры длительности сохранены\n",
    "            break\n",
    "        if frame_duration >= closest_duration:\n",
    "            # если ближайшая длительность меньше или равна длительности кадра,\n",
    "            # затем сохраняем фрейм\n",
    "            # frame_duration_formatted = format_timedelta(timedelta(seconds=frame_duration))\n",
    "            # only_file_name = filename.split(\"/\")[-1]\n",
    "            uid_frame = uuid.uuid1()\n",
    "            frame_name = f\"frame_{uid_frame}.jpg\"\n",
    "            frame_insert_count += 1\n",
    "\n",
    "            cv2.imwrite(os.path.join(dirname_str, frame_name), frame)\n",
    "            # удалить точку продолжительности из списка, так как эта точка длительности уже сохранена\n",
    "            try:\n",
    "                saving_frames_durations.pop(0)\n",
    "            except IndexError:\n",
    "                pass\n",
    "        # увеличить количество кадров\n",
    "        count += 1\n",
    "    return dirname_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T14:39:50.688498Z",
     "iopub.status.busy": "2024-06-05T14:39:50.688189Z",
     "iopub.status.idle": "2024-06-05T14:39:57.433368Z",
     "shell.execute_reply": "2024-06-05T14:39:57.432585Z",
     "shell.execute_reply.started": "2024-06-05T14:39:50.688475Z"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# модель кодировщика, которая обрабатывает изображение и возвращает его фичи\n",
    "\n",
    "# encoder_model = \"WinKawaks/vit-small-patch16-224\"\n",
    "# encoder_model = \"google/vit-base-patch16-224\"\n",
    "# encoder_model = \"google/vit-base-patch16-224-in21k\"\n",
    "encoder_model = \"microsoft/swin-base-patch4-window7-224-in22k\"\n",
    "\n",
    "# модель декодера, которая обрабатывает фичи с изображения и генерирует текст подписи\n",
    "\n",
    "# decoder_model = \"bert-base-uncased\"\n",
    "# decoder_model = \"prajjwal1/bert-tiny\"\n",
    "decoder_model = \"gpt2\"\n",
    "\n",
    "# Инициализируем токенайзер\n",
    "# tokenizer = AutoTokenizer.from_pretrained(decoder_model)\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(decoder_model)\n",
    "# tokenizer = BertTokenizerFast.from_pretrained(decoder_model)\n",
    "# Загружаем обработчик изображений\n",
    "image_processor = ViTImageProcessor.from_pretrained(encoder_model)\n",
    "\n",
    "# Используя pipeline api\n",
    "image_captioner = pipeline(\"image-to-text\", model=\"Abdou/vit-swin-base-224-gpt2-image-captioning\")\n",
    "image_captioner.model = image_captioner.model.to(device)\n",
    "\n",
    "\n",
    "# функция инференса\n",
    "def get_caption_by_image(model, image_processor, tokenizer, image_path):\n",
    "    image = load_image(image_path)\n",
    "    # предобработка\n",
    "    img = image_processor(image, return_tensors=\"pt\").to(device)\n",
    "    # генерируем описание\n",
    "    output = model.generate(**img)\n",
    "    # декодим вывод\n",
    "    return tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "\n",
    "\n",
    "# функция для получения краткого описания\n",
    "def get_short_description(string):\n",
    "    i = 255\n",
    "    if len(string) > 255:\n",
    "        while i > 0:\n",
    "            if len(string) > 255:\n",
    "                if string[i] not in [' ', '.', ',']:\n",
    "                    i -= 1\n",
    "                else:\n",
    "                    break\n",
    "    return string[:i]\n",
    "\n",
    "\n",
    "def get_video_caption(video_file):\n",
    "    directory_name = create_temp_directory_with_frames(video_file)\n",
    "    # объявим массив, в который будем складывать результаты предсказаний по фреймам\n",
    "    full_english_descriptions = []\n",
    "    for dirname, _, filenames in os.walk(directory_name):\n",
    "        for filename in filenames:\n",
    "            full_name = os.path.join(dirname, filename)\n",
    "            file_english_description = get_caption_by_image(image_captioner.model, image_processor, tokenizer, full_name)\n",
    "            full_english_descriptions.append(file_english_description)\n",
    "    # удаляем temp директорию\n",
    "    shutil.rmtree(directory_name)\n",
    "\n",
    "    # избавляемся от явных дублей\n",
    "    full_english_descriptions = list(set(full_english_descriptions))\n",
    "\n",
    "    full_russian_descriptions = translate_frames_caption(full_english_descriptions)\n",
    "    descriptions_length = len(full_russian_descriptions) - 1\n",
    "\n",
    "    random_frame_number = random.randint(0, descriptions_length)\n",
    "\n",
    "    random_russian_description = full_russian_descriptions[random_frame_number]\n",
    "    random_english_description = full_english_descriptions[random_frame_number]\n",
    "\n",
    "    full_description_en = ' '.join(full_english_descriptions)\n",
    "    full_description_ru = ' '.join(full_russian_descriptions)\n",
    "\n",
    "    return {\n",
    "        'description_ru': full_description_ru,\n",
    "        'short_description_ru': random_russian_description,\n",
    "        'description_en': full_description_en,\n",
    "        'short_description_en': random_english_description\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T15:16:03.761344Z",
     "iopub.status.busy": "2024-06-05T15:16:03.760719Z",
     "iopub.status.idle": "2024-06-05T15:16:03.771305Z",
     "shell.execute_reply": "2024-06-05T15:16:03.770317Z",
     "shell.execute_reply.started": "2024-06-05T15:16:03.761311Z"
    }
   },
   "outputs": [],
   "source": [
    "invalided_links = {\n",
    "    'link': [],\n",
    "    'row_number': []\n",
    "}\n",
    "\n",
    "\n",
    "links = []\n",
    "descriptions_ru = []\n",
    "short_descriptions_ru = []\n",
    "descriptions_en = []\n",
    "short_descriptions_en = []\n",
    "tags = []\n",
    "texts = []\n",
    "\n",
    "def enrich(row):\n",
    "    start_time = time.time()\n",
    "    link = row['link']\n",
    "    result_caption = get_video_caption(link)\n",
    "    text = transcribe_video(link)\n",
    "    result_caption['text'] = text\n",
    "    print(\"--- Вот за столько секунд обработали %s  запись ---\" % (time.time() - start_time))\n",
    "    return result_caption\n",
    "\n",
    "\n",
    "def try_to_enrich(row, index):\n",
    "    link = row['link']\n",
    "    try:\n",
    "        result = enrich(row)\n",
    "        links.append(link)\n",
    "        tags.append(row['description'])\n",
    "        descriptions_ru.append(result['description_ru'])\n",
    "        short_descriptions_ru.append(result['short_description_ru'])\n",
    "        descriptions_en.append(result['description_en'])\n",
    "        short_descriptions_en.append(result['short_description_en'])\n",
    "        texts.append(result['text'])\n",
    "    except Exception as inst:\n",
    "        print('УПАЛИИИ')\n",
    "        print(type(inst))\n",
    "        print(inst.args)\n",
    "        print(inst)\n",
    "        invalided_links['link'].append(link)\n",
    "        invalided_links['row_number'].append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T15:16:20.748879Z",
     "iopub.status.busy": "2024-06-05T15:16:20.748533Z",
     "iopub.status.idle": "2024-06-05T15:28:05.169633Z",
     "shell.execute_reply": "2024-06-05T15:28:05.168552Z",
     "shell.execute_reply.started": "2024-06-05T15:16:20.748855Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-russian were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-russian and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Вот за столько секунд обработали 17.595946073532104  запись ---\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m current_number \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m+\u001b[39m j\n\u001b[1;32m      9\u001b[0m row \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39miloc[current_number]\n\u001b[0;32m---> 10\u001b[0m try_to_enrich(row, current_number)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(current_number)\n\u001b[1;32m     12\u001b[0m j \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[12], line 28\u001b[0m, in \u001b[0;36mtry_to_enrich\u001b[0;34m(row, index)\u001b[0m\n\u001b[1;32m     26\u001b[0m link \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 28\u001b[0m     result \u001b[38;5;241m=\u001b[39m enrich(row)\n\u001b[1;32m     29\u001b[0m     links\u001b[38;5;241m.\u001b[39mappend(link)\n\u001b[1;32m     30\u001b[0m     tags\u001b[38;5;241m.\u001b[39mappend(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[12], line 19\u001b[0m, in \u001b[0;36menrich\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     17\u001b[0m link \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m result_caption \u001b[38;5;241m=\u001b[39m get_video_caption(link)\n\u001b[0;32m---> 19\u001b[0m text \u001b[38;5;241m=\u001b[39m transcribe_video(link)\n\u001b[1;32m     20\u001b[0m result_caption[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m text\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Вот за столько секунд обработали \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m  запись ---\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time))\n",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m, in \u001b[0;36mtranscribe_video\u001b[0;34m(input_video)\u001b[0m\n\u001b[1;32m     10\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m     12\u001b[0m audio \u001b[38;5;241m=\u001b[39m whisperx\u001b[38;5;241m.\u001b[39mload_audio(input_video)\n\u001b[0;32m---> 13\u001b[0m result \u001b[38;5;241m=\u001b[39m whisper_model\u001b[38;5;241m.\u001b[39mtranscribe(audio, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mru\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m model_a, metadata \u001b[38;5;241m=\u001b[39m whisperx\u001b[38;5;241m.\u001b[39mload_align_model(language_code\u001b[38;5;241m=\u001b[39mresult[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m], device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     16\u001b[0m result \u001b[38;5;241m=\u001b[39m whisperx\u001b[38;5;241m.\u001b[39malign(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegments\u001b[39m\u001b[38;5;124m\"\u001b[39m], model_a, metadata, audio, device, return_char_alignments\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/whisperx/asr.py:218\u001b[0m, in \u001b[0;36mFasterWhisperPipeline.transcribe\u001b[0;34m(self, audio, batch_size, num_workers, language, task, chunk_size, print_progress, combined_progress)\u001b[0m\n\u001b[1;32m    216\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m batch_size \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_size\n\u001b[1;32m    217\u001b[0m total_segments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(vad_segments)\n\u001b[0;32m--> 218\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, out \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(data(audio, vad_segments), batch_size\u001b[38;5;241m=\u001b[39mbatch_size, num_workers\u001b[38;5;241m=\u001b[39mnum_workers)):\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m print_progress:\n\u001b[1;32m    220\u001b[0m         base_progress \u001b[38;5;241m=\u001b[39m ((idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m total_segments) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m    124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[0;32m--> 125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/pipelines/base.py:1112\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1110\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1111\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1112\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[1;32m   1113\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/whisperx/asr.py:152\u001b[0m, in \u001b[0;36mFasterWhisperPipeline._forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_inputs):\n\u001b[0;32m--> 152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate_segment_batched(model_inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: outputs}\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/whisperx/asr.py:53\u001b[0m, in \u001b[0;36mWhisperModel.generate_segment_batched\u001b[0;34m(self, features, tokenizer, options, encoder_output)\u001b[0m\n\u001b[1;32m     47\u001b[0m encoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(features)\n\u001b[1;32m     49\u001b[0m max_initial_timestamp_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mround\u001b[39m(options\u001b[38;5;241m.\u001b[39mmax_initial_timestamp \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_precision)\n\u001b[1;32m     51\u001b[0m )\n\u001b[0;32m---> 53\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m     54\u001b[0m         encoder_output,\n\u001b[1;32m     55\u001b[0m         [prompt] \u001b[38;5;241m*\u001b[39m batch_size,\n\u001b[1;32m     56\u001b[0m         beam_size\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mbeam_size,\n\u001b[1;32m     57\u001b[0m         patience\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mpatience,\n\u001b[1;32m     58\u001b[0m         length_penalty\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mlength_penalty,\n\u001b[1;32m     59\u001b[0m         max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m     60\u001b[0m         suppress_blank\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39msuppress_blank,\n\u001b[1;32m     61\u001b[0m         suppress_tokens\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39msuppress_tokens,\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     64\u001b[0m tokens_batch \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39msequences_ids[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m result]\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_batch\u001b[39m(tokens: List[List[\u001b[38;5;28mint\u001b[39m]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DATASET_PATH = './2024_400k.csv'\n",
    "dataset = pd.read_csv(DATASET_PATH).copy()\n",
    "\n",
    "batch = 10\n",
    "for i in range(0, 50, batch):\n",
    "    j = 0\n",
    "    while j < batch:\n",
    "        current_number = i + j\n",
    "        row = dataset.iloc[current_number]\n",
    "        try_to_enrich(row, current_number)\n",
    "        print(current_number)\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T15:34:14.454957Z",
     "iopub.status.busy": "2024-06-05T15:34:14.454060Z",
     "iopub.status.idle": "2024-06-05T15:34:14.460834Z",
     "shell.execute_reply": "2024-06-05T15:34:14.459884Z",
     "shell.execute_reply.started": "2024-06-05T15:34:14.454921Z"
    }
   },
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T15:34:39.751351Z",
     "iopub.status.busy": "2024-06-05T15:34:39.750993Z",
     "iopub.status.idle": "2024-06-05T15:34:39.771349Z",
     "shell.execute_reply": "2024-06-05T15:34:39.770421Z",
     "shell.execute_reply.started": "2024-06-05T15:34:39.751323Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data={\n",
    "        'link': links,\n",
    "        'tags': tags,\n",
    "        'description_ru': descriptions_ru,\n",
    "        'short_description_ru': short_descriptions_ru,\n",
    "        'description_en': descriptions_en,\n",
    "        'short_description_en': short_descriptions_en,\n",
    "        'text': texts\n",
    "}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T15:34:54.545630Z",
     "iopub.status.busy": "2024-06-05T15:34:54.544887Z",
     "iopub.status.idle": "2024-06-05T15:34:54.558327Z",
     "shell.execute_reply": "2024-06-05T15:34:54.557331Z",
     "shell.execute_reply.started": "2024-06-05T15:34:54.545600Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_TEMP_PATH = '/kaggle/working/test.csv'\n",
    "DATASET_FAIL_PATH = '/kaggle/working/fail.csv'\n",
    "pd.DataFrame(data={\n",
    "        'link': links,\n",
    "        'tags': tags,\n",
    "        'description_ru': descriptions_ru,\n",
    "        'short_description_ru': short_descriptions_ru,\n",
    "        'description_en': descriptions_en,\n",
    "        'short_description_en': short_descriptions_en,\n",
    "        'text': texts\n",
    "}).to_csv(DATASET_TEMP_PATH, index=False)\n",
    "\n",
    "pd.DataFrame(data={\n",
    "    'link': invalided_links['link'],\n",
    "    'row_number': invalided_links['row_number'],\n",
    "}).to_csv(DATASET_FAIL_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5141222,
     "sourceId": 8594311,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5156150,
     "sourceId": 8614981,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
